From 54c1a4ca9ad94a4bfeedfc6d04776374a723834e Mon Sep 17 00:00:00 2001
From: Robert Ancell <robert.ancell@gmail.com>
Date: Fri, 25 Jun 2010 15:14:36 +1000
Subject: [PATCH] Add BBC Plugin
Description: add BBC plugin; by Collabora
Bug: http://bugzilla.mate.org/show_bug.cgi?id=555823

---
 bindings/python/idol.defs          |   10 +
 configure.in                        |   31 ++
 po/POTFILES.in                      |    4 +
 src/plugins/bbc/Makefile.am         |   26 +
 src/plugins/bbc/bbc.py              |   95 ++++
 src/plugins/bbc/bbc.idol-plugin.in |    9 +
 src/plugins/bbc/contentview.py      |  884 +++++++++++++++++++++++++++++++++++
 src/plugins/bbc/genres.py           |  251 ++++++++++
 8 files changed, 1310 insertions(+), 0 deletions(-)
 create mode 100644 src/plugins/bbc/Makefile.am
 create mode 100644 src/plugins/bbc/bbc.py
 create mode 100644 src/plugins/bbc/bbc.idol-plugin.in
 create mode 100644 src/plugins/bbc/contentview.py
 create mode 100644 src/plugins/bbc/genres.py

Index: idol-2.32.0/bindings/python/idol.defs
===================================================================
--- idol-2.32.0.orig/bindings/python/idol.defs	2010-09-27 14:34:31.000000000 +0200
+++ idol-2.32.0/bindings/python/idol.defs	2010-10-07 18:20:40.000000000 +0200
@@ -216,6 +216,16 @@
   (return-type "none")
 )
 
+(define-method action_set_mrl_and_play
+  (of-object "IdolObject")
+  (c-name "idol_action_set_mrl_and_play")
+  (return-type "none")
+  (parameters
+    '("const-char*" "mrl")
+    '("const-char*" "subtitle_mrl" (null-ok) (default "NULL"))
+  )
+)
+
 (define-method action_stop
   (of-object "IdolObject")
   (c-name "idol_action_stop")
Index: idol-2.32.0/configure.in
===================================================================
--- idol-2.32.0.orig/configure.in	2010-10-07 18:20:40.000000000 +0200
+++ idol-2.32.0/configure.in	2010-10-07 18:21:00.000000000 +0200
@@ -52,7 +52,7 @@
 AC_SUBST(IDOL_VERSION_MICRO)
 
 # The full list of plugins
-allowed_plugins="thumbnail screensaver ontop galago gromit lirc media-player-keys mythtv properties sidebar-test skipto sample-python sample-vala bemused youtube publish tracker pythonconsole jamendo opensubtitles screenshot brasero-disc-recorder coherence_upnp dbus-service iplayer chapters"
+allowed_plugins="thumbnail screensaver ontop galago gromit lirc media-player-keys mythtv properties sidebar-test skipto sample-python sample-vala bemused youtube publish tracker pythonconsole jamendo opensubtitles screenshot brasero-disc-recorder coherence_upnp dbus-service iplayer chapters bbc"
 
 PLUGINDIR='${libdir}/idol/plugins'
 AC_SUBST(PLUGINDIR)
@@ -491,6 +491,24 @@
 				add_plugin="0"
 			fi
 		;;
+		bbc)
+			# pygobject >= 2.15.3 for gio support
+			# pygtk >= 2.13.0 for gtk_tree_view_get_tooltip_context support
+			PKG_CHECK_MODULES([BBC],
+				[ pygobject-2.0 >= 2.15.3 gst-python-0.10 >= 0.10.11 pygtk-2.0 >= 2.13.0 ],
+				[ HAVE_BBCSTUFF=yes ], [ HAVE_BBCSTUFF=no ])
+			if test "x$HAVE_BBCSTUFF" != "xyes"; then
+				plugin_error_or_ignore "you need pygobject-2.0 >= 2.15.3 and gst-python-0.10 >= 0.10.11 and pygtk-2.0 >= 2.13.0 installed for the BBC plugin"
+				add_plugin="0"
+			fi
+			for pymodule in rdflib.Graph xdg
+			do
+				if ! $PYTHON -c "import $pymodule" 2>/dev/null >/dev/null; then
+					plugin_error_or_ignore "you need the python $pymodule module installed for the BBC plugin"
+					add_plugin="0"
+				fi
+			done
+		;;
 		bemused)
 			PKG_CHECK_MODULES(BEMUSED, bluez, [HAVE_BLUEZ=yes], [HAVE_BLUEZ=no])
 			if test "${HAVE_BLUEZ}" != "yes" ; then
@@ -814,6 +832,7 @@
 lib/Makefile
 src/Makefile
 src/plugins/Makefile
+src/plugins/bbc/Makefile
 src/plugins/bemused/Makefile
 src/plugins/coherence_upnp/Makefile
 src/plugins/dbus-service/Makefile
Index: idol-2.32.0/po/POTFILES.in
===================================================================
--- idol-2.32.0.orig/po/POTFILES.in	2010-09-27 14:34:31.000000000 +0200
+++ idol-2.32.0/po/POTFILES.in	2010-10-07 18:20:40.000000000 +0200
@@ -38,6 +38,10 @@
 src/backend/video-utils.c
 src/plugins/idol-plugin-manager.c
 src/plugins/idol-plugins-engine.c
+[type: gettext/ini]src/plugins/bbc/bbc.idol-plugin.in
+src/plugins/bbc/bbc.py
+src/plugins/bbc/contentview.py
+src/plugins/bbc/genres.py
 [type: gettext/ini]src/plugins/bemused/bemused.idol-plugin.in
 src/plugins/bemused/idol-bemused.c
 src/plugins/brasero-disc-recorder/idol-disc-recorder.c
Index: idol-2.32.0/src/plugins/bbc/Makefile.am
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ idol-2.32.0/src/plugins/bbc/Makefile.am	2010-10-07 18:20:40.000000000 +0200
@@ -0,0 +1,26 @@
+plugindir = $(PLUGINDIR)/bbc
+plugin_PYTHON = bbc.py contentview.py genres.py
+
+plugin_in_files = bbc.idol-plugin.in
+
+%.idol-plugin: %.idol-plugin.in $(INTLTOOL_MERGE) $(wildcard $(top_srcdir)/po/*po) ; $(INTLTOOL_MERGE) $(top_srcdir)/po $< $@ -d -u -c $(top_builddir)/po/.intltool-merge-cache
+
+plugin_DATA = $(plugin_in_files:.idol-plugin.in=.idol-plugin)
+
+EXTRA_DIST = $(plugin_in_files) bbc.py contentview.py genres.py
+
+CLEANFILES = $(plugin_DATA)
+DISTCLEANFILES = $(plugin_DATA)
+
+
+pychecker:
+	PYTHONPATH=$(top_srcdir)/src/plugins/bbc:$$PYTHONPATH \
+	pychecker $(wildcard $(top_srcdir)/src/plugins/bbc/*py)
+
+pyflakes:
+	pyflakes $(wildcard $(top_srcdir)/src/plugins/bbc/*py)
+
+check: pychecker pyflakes
+	echo
+
+
Index: idol-2.32.0/src/plugins/bbc/bbc.py
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ idol-2.32.0/src/plugins/bbc/bbc.py	2010-10-07 18:20:40.000000000 +0200
@@ -0,0 +1,95 @@
+#!/usr/bin/python
+# coding=UTF-8
+#
+# Copyright (C) 2008 Tim-Philipp Müller <tim.muller@collabora.co.uk>
+# Copyright (C) 2008 Canonical Ltd.
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 2 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program; if not, write to the Free Software
+# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.
+#
+# The Idol project hereby grant permission for non-gpl compatible GStreamer
+# plugins to be used and distributed together with GStreamer and Idol. This
+# permission are above and beyond the permissions granted by the GPL license
+# Idol is covered by.
+#
+# See license_change file for details.
+
+import gobject
+gobject.threads_init()
+import pygst
+pygst.require ("0.10")
+import gst
+
+import idol
+import gtk
+import mateconf
+import time
+import os
+from contentview import ContentView
+
+class BBCViewer(idol.Plugin):
+	def __init__ (self):
+		idol.Plugin.__init__ (self)
+		self.loaded_content = False
+
+	def mapped (self, contentview):
+		gst.log('mapped')
+		if not self.loaded_content:
+		  self.view.load()
+		  self.loaded_content = True
+
+	def activate (self, idol_object):
+		self.mateconf_client = mateconf.client_get_default ()
+		self.idol = idol_object
+                self.view = ContentView()
+		self.view.connect('play-episode', self.playEpisode)
+		vbox = gtk.VBox()
+                scrollwin = gtk.ScrolledWindow()
+                scrollwin.add(self.view)
+                scrollwin.set_policy(gtk.POLICY_NEVER, gtk.POLICY_AUTOMATIC)
+                scrollwin.set_shadow_type(gtk.SHADOW_ETCHED_IN)
+                vbox.pack_start(scrollwin, True, True)
+		vbox.show_all ()
+		idol_object.add_sidebar_page ("bbc", _("BBC"), vbox)
+		# connect to 'map' only after adding the sidebar page
+		self.view.connect('map', self.mapped)
+		gst.log('activated')
+
+	def deactivate (self, idol_object):
+		idol_object.remove_sidebar_page ("bbc")
+		self.loaded_content = False
+
+	def getConnectionSpeed(self):
+		speed_map = [ 14400, 19200, 28800, 33600, 34400,
+		              56000, 112000, 256000, 384000, 512000,
+		              1536000, 10752000 ]
+		speed_enum = self.mateconf_client.get_int("/apps/idol/connection_speed")
+		if speed_enum >= 0 and speed_enum < len(speed_map):
+		  speed_kbps = speed_map[speed_enum] / 1000
+		else:
+		  speed_kbps = 0
+		gst.log('Configured connection speed #%d: %d kbit/s' % (speed_enum, speed_kbps))
+		return speed_kbps
+
+	def playEpisode (self, view, episode):
+		gst.info('Playing episode ' + episode.title)
+		mrl = episode.getUri(self.getConnectionSpeed())
+		if mrl:
+		  gst.log('Playing uri ' + mrl)
+		  self.idol.action_set_mrl_and_play(mrl, None)
+		  #self.idol.action_remote(idol.REMOTE_COMMAND_ENQUEUE, mrl)
+		  #self.idol.action_remote(idol.REMOTE_COMMAND_PLAY, mrl)
+		else:
+		  gst.error('No uri for episode ' + episode.title)
+
Index: idol-2.32.0/src/plugins/bbc/bbc.idol-plugin.in
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ idol-2.32.0/src/plugins/bbc/bbc.idol-plugin.in	2010-10-07 18:20:40.000000000 +0200
@@ -0,0 +1,9 @@
+[Idol Plugin]
+Loader=python
+Module=bbc
+IAge=1
+_Name=BBC content viewer
+_Description=Watch or listen to selected video and audio content made available by the British Broadcasting Corporation (BBC)
+Authors=Tim-Philipp Müller <tim.muller@collabora.co.uk>
+Copyright=Copyright © 2008 Tim-Philipp Müller and Canonical Ltd. 
+Website=http://www.mate.org/projects/idol/
Index: idol-2.32.0/src/plugins/bbc/contentview.py
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ idol-2.32.0/src/plugins/bbc/contentview.py	2010-10-07 18:20:40.000000000 +0200
@@ -0,0 +1,884 @@
+#!/usr/bin/python
+# coding=UTF-8
+#
+# Copyright (C) 2008 Tim-Philipp Müller <tim.muller@collabora.co.uk>
+# Copyright (C) 2008 Canonical Ltd.
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 2 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program; if not, write to the Free Software
+# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.
+#
+# The Idol project hereby grant permission for non-gpl compatible GStreamer
+# plugins to be used and distributed together with GStreamer and Idol. This
+# permission are above and beyond the permissions granted by the GPL license
+# Idol is covered by.
+#
+# See license_change file for details.
+#
+# TODO:
+#  - clean up code: mixed studlyCaps and foo_bar; mixed callbacks and signals
+
+import gobject
+gobject.threads_init()
+import glib
+import gio
+import pygst
+pygst.require ("0.10")
+import gst
+import gtk
+import pango
+
+import os
+import dircache
+import errno
+import random
+import time
+import thread
+
+from rdflib.Graph import ConjunctiveGraph
+from rdflib import Namespace
+from rdflib import RDF
+
+from xdg import BaseDirectory
+
+import genres
+
+'''
+Define namespaces we will be using globally
+'''
+DC = Namespace('http://purl.org/dc/elements/1.1/')
+PO = Namespace('http://purl.org/ontology/po/')
+OWL = Namespace('http://www.w3.org/2002/07/owl#')
+FOAF = Namespace('http://xmlns.com/foaf/0.1/')
+PLAY = Namespace('http://uriplay.org/elements/')
+
+
+'''
+Container/Audio/Video codec mappings - global for readability
+'''
+
+# FIXME: Real Media formats
+container_map = { 'application/ogg' : 'application/ogg',
+                  'audio/ogg' : 'application/ogg',
+                  'video/ogg' : 'application/ogg',
+                  'video/x-ms-asf' : 'video/x-ms-asf',
+                  'audio/x-ms-asf' : 'video/x-ms-asf',
+                  'audio/mp3' : 'audio/mpeg, mpegversion=(int)1, layer=(int)3',
+                  'audio/mp4' : 'audio/x-m4a',
+                  'audio/mpeg' : 'audio/mpeg, mpegversion=(int)1',
+                  'video/x-flv' : 'video/x-flv',
+                  'video/3gpp' : 'application/x-3gp',
+                  'application/x-3gp' : 'application/x-3gp',
+                  'audio/x-matroska' : 'video/x-matroska',
+                  'video/x-matroska' : 'video/x-matroska',
+                  'video/mp4' : 'video/quicktime',
+                  'video/mpeg' : 'video/mpeg, mpegversion=(int)1, ' +
+                                 ' systemstream=(boolean)true;   ' + 
+                                 'video/mpeg, mpegversion=(int)2, ' +
+                                  ' systemstream=(boolean)true',
+                  'video/mpeg2' : 'video/mpeg, mpegversion=(int)2,' +
+                                  ' systemstream=(boolean)false',
+                  'video/mp2t' : 'video/mpegts',
+                  'video/mpegts' : 'video/mpegts' }
+
+# FIXME: do we need both parsed=true and parsed=false for mp3?
+audio_map = { 'audio/mp1' : 'audio/mpeg, mpegversion=(int)1, layer=(int)1',
+              'audio/mp2' : 'audio/mpeg, mpegversion=(int)1, layer=(int)2',
+              'audio/mp3' : 'audio/mpeg, mpegversion=(int)1, layer=(int)3',
+              'audio/mp4' : 'audio/mpeg, mpegversion=(int)2; ' +
+                            'audio/mpeg, mpegversion=(int)4',
+              'audio/mpeg' : 'audio/mpeg, mpegversion=(int)1, layer=(int)3',
+              'audio/x-wma' : 'audio/x-wma, wmaversion=(int)1; ' +
+                              'audio/x-wma, wmaversion=(int)2',
+              'audio/x-wmv' : 'audio/x-wma, wmaversion=(int)1; ' +
+                              'audio/x-wma, wmaversion=(int)2',
+              'audio/x-ms-wma' : 'audio/x-wma, wmaversion=(int)1; ' +
+                                 'audio/x-wma, wmaversion=(int)2',
+              'audio/x-ms-wmv' : 'audio/x-wma, wmaversion=(int)1; ' +
+                                 'audio/x-wma, wmaversion=(int)2',
+              'audio/vorbis' : 'audio/x-vorbis' }
+
+# FIXME: video/x-ms-wmv: ask if this refers to a particular wmv version or if it can be any version/profile
+# BBC regard video/x-svq as equivalent to video/x-flash-video, so we just
+# treat them all the same here and require all of them in this case
+video_map = { 'video/x-vp6' : 'video/x-vp6',
+              'video/x-flash-video' : 'video/x-svq, svqversion=(int)1; ' +
+                                      'video/x-svq, svqversion=(int)3; ' +
+                                      'video/x-flash-video, flvversion=(int)1',
+              'video/H263-200' : 'video/x-svq, svqversion=(int)1; ' +
+                                 'video/x-flash-video, flvversion=(int)1',
+              'video/x-svq' : 'video/x-svq, svqversion=(int)1; ' +
+                              'video/x-svq, svqversion=(int)3; ' +
+                              'video/x-flash-video, flvversion=(int)1',
+              'video/H264' : 'video/x-h264',
+              'video/mpeg' : 'video/mpeg, mpegversion=(int)1, ' +
+                             ' systemstream=(boolean)false;   ' + 
+                             'video/mpeg, mpegversion=(int)2, ' +
+                              ' systemstream=(boolean)false',
+              'video/mpeg1' : 'video/mpeg, mpegversion=(int)1, ' +
+                              ' systemstream=(boolean)false',
+              'video/mpeg2' : 'video/mpeg, mpegversion=(int)2, ' +
+                              ' systemstream=(boolean)false',
+              'video/x-dirac' : 'video/x-dirac',
+              'video/x-wmv' : 'video/x-wmv, wmvversion=(int)1; ' +
+                              'video/x-wmv, wmvversion=(int)2; ' +
+                              'video/x-wmv, wmvversion=(int)3',
+              'video/x-ms-wmv' : 'video/x-wmv, wmvversion=(int)1; ' +
+                                 'video/x-wmv, wmvversion=(int)2; ' +
+                                 'video/x-wmv, wmvversion=(int)3' }
+
+###############################################################################
+
+'''
+UriPlayObject: base class for Brand, Episode, Encoding, Location etc.
+'''
+class UriPlayObject(object):
+    __slots__ = [ 'rdf_attribute_mapping' ]
+
+    def __init__(self):
+        self.rdf_attribute_mapping = []
+
+    def parseProperties(self, conjunctive_graph, graph_obj):
+        for rdf_tag, prop_name in self.rdf_attribute_mapping:
+          self.__setattr__(prop_name, None)
+        for rdf_tag, prop_name in self.rdf_attribute_mapping:
+          for match in conjunctive_graph.objects(graph_obj, rdf_tag):
+            self.__setattr__(prop_name, match.encode('utf-8'))
+            break # we can handle only one value for each property name
+
+###############################################################################
+
+'''
+Brand: a show/series/group of episodes
+'''
+class Brand(UriPlayObject):
+    __slots__ = [ 'title', 'description', 'episodes', 'genres' ]
+
+    def __init__(self):
+        self.episodes = []
+        self.genres = []
+        self.rdf_attribute_mapping = [ ( DC['title'], 'title' ),
+                                       ( DC['description'], 'description' ) ]
+
+    def parseBrand(self, conjunctive_graph, graph_brand):
+        self.parseProperties(conjunctive_graph, graph_brand)
+
+        self.episodes = []
+        for e in conjunctive_graph.objects(graph_brand, PO['episode']):
+          episode = Episode()
+          episode.parseEpisode(conjunctive_graph, e)
+          self.episodes.append(episode)
+
+        self.genres = []
+        for match in conjunctive_graph.objects(graph_brand, PO['genre']):
+          genre_utf8 = match.encode('utf-8')
+          pos = genre_utf8.find('/genres/')
+          if pos > 0:
+            pos += len('/genres/')
+            genre = genre_utf8[pos:]
+          else:
+            gst.warning('Unexpected genre identifier: ' + genre_utf8)
+            genre = 'other'
+          if genre not in self.genres:
+            self.genres.append(genre)
+
+    def hasUsableEpisodes(self):
+        return len(self.episodes) > 0
+
+    def getUsableEpisodes(self):
+        usable_episodes = []
+        for episode in self.episodes:
+          if episode.hasUsableEncodings():
+            usable_episodes.append(episode)
+        return usable_episodes
+
+###############################################################################
+
+'''
+Episode: a single episode of a Brand (even though we parse the different
+         versions, for now we'll just pretend there is only one version and
+         map the encodings attribute to the encodings of the first version
+         we find, to make things easier)
+'''
+class Episode(UriPlayObject):
+    __slots__ = [ 'title', 'description', 'versions', 'encodings' ]
+
+    def __init__(self):
+        self.encodings = []
+        self.rdf_attribute_mapping = [ ( DC['title'], 'title' ),
+                                       ( DC['description'], 'description' ) ]
+
+    def parseEpisode(self, conjunctive_graph, graph_episode):
+        self.parseProperties(conjunctive_graph, graph_episode)
+        self.versions = []
+        for v in conjunctive_graph.objects(graph_episode, PO['version']):
+          version = EpisodeVersion()
+          version.parseVersion(conjunctive_graph, v)
+          self.versions.append(version)
+          # encodings of episode = encodings of first version of episode
+          if not self.encodings:
+            self.encodings = version.encodings
+
+    # TODO: this does not take into account codec quality, highest bitrate wins
+    def getBestEncoding(self, connection_speed=0):
+        gst.log('connection speed: %d kbit/s' % (connection_speed))
+        best_encoding = None
+        for encoding in self.encodings:
+          gst.log('have encoding with bitrate: %d kbit/s' % (encoding.getBitrate()))
+          if best_encoding:
+            if encoding.getBitrate() > best_encoding.getBitrate():
+              if connection_speed <= 0 or encoding.getBitrate() <= connection_speed:
+                best_encoding = encoding
+          else:
+            best_encoding = encoding
+        if best_encoding:
+          gst.log('best encoding has bitrate of %d kbit/s' % (best_encoding.getBitrate()))  
+        return best_encoding
+
+    def getUri(self, connection_speed=0):
+        encoding = self.getBestEncoding(connection_speed)
+        if encoding:
+          location = encoding.getBestLocation()
+          if location:
+            return location.uri
+        return None
+
+###############################################################################
+
+'''
+EpisodeVersion: a version of an Episode (e.g. UK vs. US or pg-13 vs. 18)
+'''
+class EpisodeVersion(UriPlayObject):
+    __slots__ = [ 'encodings' ]
+
+    def __init__(self):
+        self.encodings = []
+        self.rdf_attribute_mapping = []
+
+    def parseVersion(self, conjunctive_graph, graph_version):
+        self.parseProperties(conjunctive_graph, graph_version)
+        self.encodings = []
+        for e in conjunctive_graph.objects(graph_version, PLAY['manifestedAs']):
+          encoding = Encoding()
+          encoding.parseEncoding(conjunctive_graph, e)
+          self.encodings.append(encoding)
+
+###############################################################################
+
+'''
+Encoding: a specific encoding of an Episode (format/bitrate/size etc.)
+'''
+class Encoding(UriPlayObject):
+    __slots__ = [ 'container_format', 'bitrate', 'size', 'video_codec',
+                  'video_bitrate', 'video_fps', 'video_height', 'video_width',
+                  'audio_codec', 'audio_bitrate', 'audio_channels',
+                  'locations', 'required_caps' ]
+
+    def __init__(self):
+        self.required_caps = None
+        self.rdf_attribute_mapping = [
+            ( PLAY['dataContainerFormat'], 'container_format' ),
+            ( PLAY['bitRate'], 'bitrate' ),
+            ( PLAY['dataSize'], 'size' ),
+            ( PLAY['videoCoding'], 'video_codec' ),
+            ( PLAY['videoBitrate'], 'video_bitrate' ),
+            ( PLAY['videoFrameRate'], 'video_fps' ),
+            ( PLAY['videoVerticalSize'], 'video_height' ),
+            ( PLAY['videoHorizontalSize'], 'video_width' ),
+            ( PLAY['audioCoding'], 'audio_codec' ),
+            ( PLAY['audioBitrate'], 'audio_bitrate' ),
+            ( PLAY['audioChannels'], 'audio_channels' )]
+
+    def parseEncoding(self, conjunctive_graph, graph_encoding):
+        self.parseProperties(conjunctive_graph, graph_encoding)
+        self.locations = []
+        for l in conjunctive_graph.objects(graph_encoding, PLAY['availableAt']):
+          location = Location()
+          location.parseLocation(conjunctive_graph, l)
+          self.locations.append(location)
+          self.required_caps = self.postProcessCodecs()
+
+    def postProcessCodecs(self):
+        required_caps = gst.Caps()
+        if self.video_codec:
+          self.video_codec = self.video_codec.lower()
+          if self.video_codec in video_map:
+            required_caps.append(gst.Caps(video_map[self.video_codec]))
+          else:
+            gst.warning('unmapped video codec ' + self.video_codec)
+            return None
+        if self.audio_codec:
+          self.audio_codec = self.audio_codec.lower()
+          if self.audio_codec in audio_map:
+            required_caps.append(gst.Caps(audio_map[self.audio_codec]))
+          else:
+            gst.warning('unmapped audio codec ' + self.audio_codec)
+            return None
+        if self.container_format:
+          self.container_format = self.container_format.lower()
+          if self.container_format in container_map:
+            required_caps.append(gst.Caps(container_map[self.container_format]))
+          else:
+            gst.warning('unmapped container format ' + self.container_format)
+            return None
+
+        if not required_caps.is_empty():
+          return required_caps
+        else:
+          return None
+
+    def getBitrate(self):
+      if not self.bitrate:
+        return 0
+      return eval(self.bitrate)
+
+    def getBestLocation(self):
+        locations = self.locations
+        random.shuffle(locations)
+        for loc in locations:
+          if loc.isUsable():
+            return loc
+        return None
+
+###############################################################################
+
+'''
+Location: location (URI) of a specific encoding
+'''
+class Location(UriPlayObject):
+    __slots__ = [ 'uri', 'type', 'sub_type', 'is_live' ]
+
+    # Note: type, subType and isLive are more often not available than available
+    def __init__(self):
+        self.rdf_attribute_mapping = [
+            ( PLAY['uri'], 'uri' ),
+            ( PLAY['transportType'], 'type' ),
+            ( PLAY['transportSubType'], 'sub_type' ),
+            ( PLAY['transportIsLive'], 'is_live' )]
+
+    def parseLocation(self, conjunctive_graph, graph_location):
+        self.parseProperties(conjunctive_graph, graph_location)
+
+    def isUsable(self):
+        if self.uri and self.uri.startswith('http'):
+          return True
+        return False
+
+###############################################################################
+
+'''
+ContentPool: downloads rdf file with available content and caches it locally,
+             then parses the file and announces new brands and brands where
+             the episode listing has changed. The cached file is saved with
+             the ETag from the server/gio as part of the filename, so we can
+             easily compare the tag to the server's later to check if we have
+             to update the file or not (not that ETag here means what we get
+             from the gio.FileInfo on the remote uri, and never refers to a
+             gio-generated ETag for the local cache file, since those two
+             are not comparable)
+'''
+# TODO:
+#  - maybe derive from list store or filtermodel directly?
+class ContentPool(gobject.GObject):
+    __slots__ = [ 'cache_dir', 'brands' ]
+
+    __gsignals__ = dict(codec_cache_loaded=(gobject.SIGNAL_RUN_LAST, None, ()),
+                        progress_message=(gobject.SIGNAL_RUN_LAST, None, (str, )),
+                        loading_error=(gobject.SIGNAL_RUN_LAST, None, (str, )),
+                        loading_done=(gobject.SIGNAL_RUN_LAST, None, ()))
+
+    CACHE_FILE_PREFIX = 'content-'
+    CACHE_FILE_SUFFIX = '.cache'
+    AVAILABLE_CONTENT_URI = 'http://open.bbc.co.uk/rad/uriplay/availablecontent'
+    MAX_CACHE_FILE_AGE = 2*3600  # 2 hours
+
+    def __init__(self):
+        gobject.GObject.__init__ (self)
+
+        self.brands = []
+        self.cache_dir = os.path.join(BaseDirectory.xdg_cache_home, 'idol',
+                                      'plugins', 'bbc')
+        try:
+          os.makedirs(self.cache_dir)
+          gst.log('created cache directory ' + self.cache_dir)
+        except OSError, err:
+          if err.errno == errno.EEXIST:
+            gst.log('cache directory ' + self.cache_dir + ' already exists')
+          else:
+            gst.error('failed to create cache directory ' + self.cache_dir +
+                      ': ' + err.strerror)
+            self.cache_dir = None
+
+    ''' returns True if the given filename refers to one of our cache files '''
+    def isCacheFileName(self, filename):
+      if not filename.startswith(self.CACHE_FILE_PREFIX):
+        return False
+      if not filename.endswith(self.CACHE_FILE_SUFFIX):
+        return False
+      return True
+
+    ''' removes all cache files that don't relate to the given etag '''
+    def deleteStaleCacheFiles(self, except_etag=None):
+        try:
+          for fn in dircache.listdir(self.cache_dir):
+            if self.isCacheFileName(fn):
+              if except_etag == None or fn.find(except_etag) < 0:
+                try:
+                  gst.log('deleting stale cache file ' + fn)
+                  os.remove(os.path.join(self.cache_dir,fn))
+                except OSError:
+                  pass
+        except OSError:
+          pass
+
+    ''' finds the most recent cache file and returns its file name or None'''
+    def findMostRecentCacheFile(self):
+        best_mtime = 0
+        best_name = None
+        try:
+          gst.log('Looking for cache files in ' + self.cache_dir)
+          for fn in dircache.listdir(self.cache_dir):
+            if self.isCacheFileName(fn):
+              mtime = os.stat(os.path.join(self.cache_dir,fn)).st_mtime
+              gst.log('Found cache file %s, mtime %ld' % (fn, long(mtime)))
+              if mtime > best_mtime:
+                best_name = fn
+                best_mtime = mtime
+        except OSError, err:
+          gst.debug("couldn't inspect cache directory %s: %s" % (self.cache_dir, err.strerror))
+          return None
+
+        if not best_name:
+          gst.log('No cache file found')
+          return None
+
+        return best_name
+
+    ''' gets the ETag for the most recent cache file, or None '''
+    def getCacheETag(self):
+        etag = self.findMostRecentCacheFile()
+        if not etag:
+          return None
+        prefix_len = len(self.CACHE_FILE_PREFIX)
+        suffix_len = len(self.CACHE_FILE_SUFFIX)
+        etag = etag[prefix_len:-suffix_len]
+        gst.log('ETag: ' + etag)
+        return etag
+
+    ''' makes a full filename from an ETag '''
+    def createCacheFileName(self, etag):
+        if not etag:
+          gst.debug('No ETag, using dummy ETag as fallback')
+          etag = '000000-00000-00000000'
+        fn = self.CACHE_FILE_PREFIX + etag +  self.CACHE_FILE_SUFFIX
+        return os.path.join(self.cache_dir, fn)
+
+    def parse_async(self, cache_fn):
+        self.emit('progress-message', _('Parsing available content list ...'))
+        thread.start_new_thread(self._parsing_thread, (cache_fn, ))
+
+    def _parsing_thread(self, cache_fn):
+        def _parse_idle_cb(err_msg, brands):
+            self.brands = brands
+            gst.info('Parsing done: %d brands' % (len(self.brands)))
+            if err_msg:
+              self.emit('loading-error', err_msg)
+            else:
+              self.emit('loading-done')
+            return False
+
+        err_msg = None
+        brands = []
+        gst.debug('Loading ' + cache_fn)
+        store = ConjunctiveGraph()
+        try:
+          gst.debug('Reading RDF file ...')
+          store.load(cache_fn)
+          gst.debug('Parsing ' + cache_fn)
+          brands = self.parseBrands(store)
+        except:
+          gst.warning('Problem parsing RDF')
+          err_msg = 'Could not parse available content list'
+        finally:
+          gst.debug('Parsing done, marshalling result into main thread')
+          gobject.idle_add(_parse_idle_cb, err_msg, brands)
+
+    def _format_size_for_display(self, size):
+        if size < 1024:
+          return '%d bytes' % size
+        if size < 1024*1024:
+          return '%.1f kB' % (size / 1024.0)
+        else:
+          return '%.1f MB' % (size / (1024.0*1024.0))
+
+    def load_async(self):
+        def _query_done_cb(remote_file, result):
+            # mutable container so subfunctions can share access
+            # chunks, total_len
+            pdata = [ [], 0 ] 
+
+            def _read_async_cb(instream, result):
+                try:
+                  partial_data = instream.read_finish(result)
+                  gst.log('Read partial chunk of %d bytes' % (len(partial_data)))
+                  chunks = pdata[0]
+                  bytes_read = pdata[1]
+                  if len(partial_data) == 0:                  
+                    instream.close()
+                    outstream = cache_file.create(gio.FILE_CREATE_NONE)
+                    for chunk in chunks:
+                      outstream.write(chunk)
+                    outsize = outstream.query_info('*').get_size()
+                    outstream.close()
+                    gst.info('Wrote %ld bytes' % (outsize))
+                    self.parse_async(cache_fn)
+                  else:
+                    chunks.append(partial_data)
+                    bytes_read += len(partial_data)
+                    pdata[0] = chunks
+                    pdata[1] = bytes_read
+                    instream.read_async(10240, _read_async_cb, io_priority=glib.PRIORITY_LOW-1)
+                    self.emit('progress-message',
+                              _('Downloading available content list ... ') + '(' +
+                              self._format_size_for_display(bytes_read) + ')')
+                except IOError, e:
+                  gst.warning('Error downloading ' + self.AVAILABLE_CONTENT_URI)
+                  instream.close()
+                  try:
+                    cache_file.delete()
+                  finally:
+                    self.emit('loading-error', _('Error downloading available content list'))
+
+            # _query_done_cb start:
+            gst.log('Query done')
+            try:
+              remote_info = remote_file.query_info_finish(result)
+            except Exception, e:
+              # bail out if we can't query, not much point trying to download
+              gst.warning('Could not query %s: %s' % (self.AVAILABLE_CONTENT_URI, e.message))
+              self.emit('loading-error', _('Could not connect to server'))
+              return
+
+            gst.log('Got info, querying etag')
+            remote_etag = remote_info.get_etag()
+            if remote_etag:
+              remote_etag = remote_etag.strip('"')
+              gst.log('Remote etag: ' + remote_etag)
+
+            cache_fn = self.createCacheFileName(remote_etag)
+            cache_file = gio.File(cache_fn)
+
+            # if file already exists, get size to double-check against server's
+            try:
+              cache_size = cache_file.query_info('standard::size').get_size()
+            except:
+              cache_size = 0
+            finally:
+              if etag and remote_etag and etag == remote_etag:
+                remote_size = remote_info.get_size()
+                if remote_size <= 0 or cache_size == remote_size:
+                  gst.log('Cache file is up-to-date, nothing to do')
+                  self.parse_async(cache_fn)
+                  return
+
+            # delete old cache file if it exists
+            try:
+              cache_file.delete()
+            except:
+              pass
+
+            # FIXME: use gio.File.copy_async() once it's wrapped
+            remote_file.read().read_async(10240, _read_async_cb, io_priority=glib.PRIORITY_LOW-1)
+            gst.info('copying ' + self.AVAILABLE_CONTENT_URI + ' -> ' + cache_fn)
+            self.emit('progress-message', _('Downloading available content list ...'))
+            return
+
+        # load_async start:
+        gst.log('starting loading')
+
+        etag = self.getCacheETag()
+        if etag:
+          gst.log('Cached etag: ' + etag)
+          self.deleteStaleCacheFiles(etag)
+          existing_cache_fn = self.createCacheFileName(etag)
+          existing_cache_file = gio.File(existing_cache_fn)
+          existing_cache_info = existing_cache_file.query_info('time::modified')
+          existing_cache_mtime = existing_cache_info.get_modification_time()
+          # if the cache file is not older than N minutes/hours/days, then
+          # we'll just go ahead and use it instead of downloading a new one,
+          # even if it's not perfectly up-to-date.
+          # FIXME: UI should have a way to force an update
+          secs_since_update = time.time() - existing_cache_mtime
+          if secs_since_update >= 0 and secs_since_update < self.MAX_CACHE_FILE_AGE:
+            gst.log('Cache file is fairly recent, last updated %f secs ago' % (secs_since_update))
+            self.parse_async(existing_cache_fn)
+            return
+        else:
+          gst.log('Cached etag: None')
+
+        # CHECKME: what happens if http is not available as protocol?
+        remote_file = gio.File(self.AVAILABLE_CONTENT_URI)
+        gst.log('Contacting server ' + self.AVAILABLE_CONTENT_URI)
+        self.emit('progress-message', _('Connecting to server ...'))
+        remote_file.query_info_async(_query_done_cb, '*')
+
+    def parseBrands(self, graph):
+        brands = []
+        for b in graph.subjects(RDF.type, PO['Brand']):
+          brand = Brand()
+          brand.parseBrand(graph, b)
+          brands.append(brand)
+          gst.log('[%3d eps] %s %s' % (len(brand.episodes), brand.title, brand.genres))
+        return brands
+
+    ''' returns array of brands which can potentially be played '''
+    def getUsableBrands(self):
+        usable_brands = []
+        for brand in self.brands:
+          if brand.hasUsableEpisodes():
+            usable_brands.append(brand)
+        return usable_brands
+
+
+###############################################################################
+
+class ContentView(gtk.TreeView):
+    __slots__ = [ 'pool', 'content_pool_loaded', 'genre_pool' ]
+    __gsignals__ = dict(play_episode=
+                        (gobject.SIGNAL_RUN_LAST, None,
+                         (object,))) # Episode
+
+    SORT_ID_1 = 0
+
+    def __init__(self):
+        gtk.TreeView.__init__ (self)
+        self.setupModel()
+
+        self.set_headers_visible(False)
+
+        self.connect('row-activated', self.onRowActivated)
+
+        self.set_property('has-tooltip', True)
+        self.connect('query-tooltip', self.onQueryTooltip)
+
+        self.set_message(_('Loading ...'))
+
+        self.pool = ContentPool()
+        self.pool.connect('progress-message', self._on_content_pool_message)
+        self.pool.connect('loading-error', self._on_content_pool_error)
+        self.pool.connect('loading-done', self._on_content_pool_loading_done)
+        self.content_pool_loaded = False
+        self.genre_pool = genres.GenrePool()
+
+    def load(self):
+        self.pool.load_async()
+        gst.log('started loading')
+
+    def _on_content_pool_message(self, content_pool, msg):
+        self.set_message(msg)
+
+    def _on_content_pool_error(self, content_pool, err_msg):
+        gst.warning('Failed to load available content: ' + err_msg)
+        self.set_message(err_msg)
+
+    def _on_content_pool_loading_done(self, content_pool):
+        gst.log('content pool loaded')
+        self.content_pool_loaded = True
+        self.populate()
+
+    def populate_add_genre(self, genre, parent_iter):
+        _iter = self.store.append(parent_iter, [None, None, None, genre])
+        for child_genre in genre.children:
+          self.populate_add_genre(child_genre, _iter)
+        for brand in genre.brands:
+          brand_iter = self.store.append(_iter, [brand, None, None, None])
+          for ep in brand.episodes:
+            self.store.append(brand_iter, [brand, ep, None, None])
+        return _iter
+
+    def populate(self):
+        gst.log('populating treeview')
+
+        brands = self.pool.getUsableBrands()
+        gst.info('%d brands with usable episodes/encodings' % (len(brands)))
+
+        # build genre tree in memory and add brands to genre objects
+        self.genre_pool.clear()
+        for brand in brands:
+          for genre_shortref in brand.genres:
+            genre = self.genre_pool.get_genre(genre_shortref)
+            genre.add_brand(brand)
+
+        # add everything to the list store
+        self.store.clear()
+        toplevel_iters = []
+        for toplevel_genre in self.genre_pool.get_toplevel_genres():
+          _iter = self.populate_add_genre(toplevel_genre, None)          
+          toplevel_iters.append(_iter)
+          
+        # now make all this visible (view might be showing model with message)
+        self.set_model(self.filter)
+
+        # expand top-level categories
+        for _iter in toplevel_iters:
+          path = self.store.get_path(_iter)
+          self.expand_row(path, False)
+
+    def get_brand_tooltip(self, brand):
+      if not brand or not brand.description:
+        return None
+      return '<b>%s</b>\n<i>%s</i>' % (gobject.markup_escape_text(brand.title),
+                                        gobject.markup_escape_text(brand.description))
+
+    def get_episode_tooltip(self, brand, episode):
+      if not episode or not episode.description:
+        return None
+      return '<b>%s</b>\n<b><small>%s</small></b>\n<i>%s</i>' % (gobject.markup_escape_text(brand.title),
+                                                                 gobject.markup_escape_text(episode.title),
+                                                                 gobject.markup_escape_text(episode.description))
+
+    def onQueryTooltip(self, view, x, y, keyboard_tip, tip):
+      try:
+        model, path, _iter = self.get_tooltip_context(x, y, keyboard_tip)
+      except:
+        return False # probably no content yet
+
+      brand, episode, msg, genre = model.get(_iter, 0, 1, 2, 3)
+      if msg or genre:
+        return False
+      if brand and not episode:
+        markup = self.get_brand_tooltip(brand)
+      elif brand and episode:
+        markup = self.get_episode_tooltip(brand, episode)
+      else:
+        markup = None
+      if markup:
+        tip.set_markup(markup)
+      else:
+        tip.set_text(_('No details available'))
+      return True
+
+    def onRowActivated(self, view, path, col):
+        model = self.get_model()
+        if model:
+          _iter = model.get_iter(path)
+          brand, episode = self.get_model().get(_iter, 0, 1)
+          if episode:
+            self.emit('play-episode', episode)
+
+    def renderGenreCell(self, column, renderer, model, _iter, genre):
+        markup = '<b>%s</b>' % \
+                 (gobject.markup_escape_text(genre.label))
+        renderer.set_property('markup', markup)
+
+    def renderBrandCell(self, column, renderer, model, _iter, brand):
+        markup = '<b><small>%s <span color="LightGray">(%d)</span></small></b>' % \
+                 (gobject.markup_escape_text(brand.title), len(brand.episodes))
+        renderer.set_property('markup', markup)
+
+    def renderEpisodeCell(self, column, renderer, model, _iter, brand, episode):
+        markup = '<span><small>%s</small></span>' % (gobject.markup_escape_text(episode.title))
+        renderer.set_property('markup', markup)
+
+    def renderMessageCell(self, column, renderer, model, _iter, msg):
+        markup = '<i>%s</i>' % (gobject.markup_escape_text(msg))
+        renderer.set_property('markup', markup)
+        
+    def renderCell(self, column, renderer, model, _iter):
+        brand, episode, msg, genre = model.get(_iter, 0, 1, 2, 3)
+        if msg:
+          self.renderMessageCell(column, renderer, model, _iter, msg)
+        elif genre:
+          self.renderGenreCell(column, renderer, model, _iter, genre)
+        elif not episode:
+          self.renderBrandCell(column, renderer, model, _iter, brand)
+        else:
+          self.renderEpisodeCell(column, renderer, model, _iter, brand, episode)
+
+    # there must be a more elegant way to do this in python
+    def sortFunc(self, model, iter1, iter2):
+        brand1, episode1, genre1 = model.get(iter1, 0, 1, 3)
+        brand2, episode2, genre2 = model.get(iter2, 0, 1, 3)
+
+        # genres are sorted by genre.sort_rank
+        if genre1 and genre2:
+          if genre1.sort_rank != genre2.sort_rank:
+            return genre1.sort_rank - genre2.sort_rank
+          else:
+            s1 = genre1.label
+            s2 = genre2.label
+
+        # genre always comes before any other siblings (like brands or episodes)
+        elif genre1:
+          return -1
+        elif genre2:
+          return 1
+
+        # brands and episodes are sorted alphabetically by title
+        elif not episode1 or not episode2:
+          s1 = brand1.title
+          s2 = brand2.title
+        elif episode1 and episode2:
+          s1 = episode1.title
+          s2 = episode2.title
+        else:
+          gst.warning('should not be reached (should be genre label comparison)')
+
+        # string comparison
+        if s1 == s2:
+          return 0
+        elif s1 > s2:
+          return 1
+        else:
+          return -1
+
+    def set_message(self, msg):
+        self.msg_store.clear()
+        self.msg_store.append(None, [None, None, msg, None])
+        self.set_model(self.msg_store)
+        gst.log('set message "' + msg + '"')
+
+    def setupModel(self):
+        # columns: Brand, Episode, message string, Genre
+        self.msg_store = gtk.TreeStore(object, object, str, object)
+        self.store = gtk.TreeStore(object, object, str, object)
+        self.filter = self.store.filter_new()
+
+        column = gtk.TreeViewColumn()
+        renderer = gtk.CellRendererText()
+        renderer.set_property('ellipsize', pango.ELLIPSIZE_END)
+        column.pack_start(renderer, expand=True)
+        column.set_cell_data_func(renderer, self.renderCell)
+        self.append_column(column)
+        self.store.set_sort_func(self.SORT_ID_1, self.sortFunc)
+        self.store.set_sort_column_id(self.SORT_ID_1, gtk.SORT_ASCENDING)
+
+if __name__ == "__main__":
+    # ensure the caps strings in the container/video/audio map are parsable
+    for cs in video_map:
+      caps = gst.Caps(video_map[cs])
+    for cs in audio_map:
+      caps = gst.Caps(audio_map[cs])
+    for cs in container_map:
+      caps = gst.Caps(container_map[cs])
+    # test window
+    window = gtk.Window()
+    scrollwin = gtk.ScrolledWindow()
+    scrollwin.set_policy(gtk.POLICY_NEVER, gtk.POLICY_AUTOMATIC)
+    window.add(scrollwin)
+    view = ContentView()
+    view.load()
+    scrollwin.add(view)
+    window.show_all()
+    gtk.main()
+
Index: idol-2.32.0/src/plugins/bbc/genres.py
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ idol-2.32.0/src/plugins/bbc/genres.py	2010-10-07 18:20:40.000000000 +0200
@@ -0,0 +1,251 @@
+#!/usr/bin/python
+# coding=UTF-8
+#
+# Copyright (C) 2008 Tim-Philipp Müller <tim.muller@collabora.co.uk>
+# Copyright (C) 2008 Canonical Ltd.
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 2 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program; if not, write to the Free Software
+# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA.
+#
+# The Idol project hereby grant permission for non-gpl compatible GStreamer
+# plugins to be used and distributed together with GStreamer and Idol. This
+# permission are above and beyond the permissions granted by the GPL license
+# Idol is covered by.
+#
+# See license_change file for details.
+
+import gobject
+gobject.threads_init()
+import pygst
+pygst.require ("0.10")
+import gst
+
+shortref_to_label_map = {
+  "childrens": _("Children's"),
+  "childrens/activities": _("Activities"),
+  "childrens/drama": _("Drama"),
+  "childrens/entertainmentandcomedy": _("Entertainment & Comedy"),
+  "childrens/factual": _("Factual"),
+  "childrens/music": _("Music"),
+  "childrens/news": _("News"),
+  "childrens/sport": _("Sport"),
+  "drama": _("Drama"),
+  "drama/actionandadventure": _("Action & Adventure"),
+  "drama/biographical": _("Biographical"),
+  "drama/classicandperiod": _("Classic & Period"),
+  "drama/crime": _("Crime"),
+  "drama/historical": _("Historical"),
+  "drama/horrorandsupernatural": _("Horror & Supernatural"),
+  "drama/legalandcourtroom": _("Legal & Courtroom"),
+  "drama/medical": _("Medical"),
+  "drama/musical": _("Musical"),
+  "drama/political": _("Political"),
+  "drama/psychological": _("Psychological"),
+  "drama/relationshipsandromance": _("Relationships & Romance"),
+  "drama/scifiandfantasy": _("SciFi & Fantasy"),
+  "drama/soaps": _("Soaps"),
+  "drama/spiritual": _("Spiritual"),
+  "drama/thriller": _("Thriller"),
+  "drama/waranddisaster": _("War & Disaster"),
+  "drama/western": _("Western"),
+  "entertainmentandcomedy": _("Entertainment & Comedy"),
+  "entertainmentandcomedy/impressionists": _("Impressionists"),
+  "entertainmentandcomedy/satire": _("Satire"),
+  "entertainmentandcomedy/sitcoms": _("Sitcoms"),
+  "entertainmentandcomedy/sketch": _("Sketch"),
+  "entertainmentandcomedy/spoof": _("Spoof"),
+  "entertainmentandcomedy/standup": _("Standup"),
+  "entertainmentandcomedy/varietyshows": _("Variety Shows"),
+  "factual": _("Factual"),
+  "factual/antiques": _("Antiques"),
+  "factual/artscultureandthemedia": _("Arts, Culture & the Media"),
+  "factual/beautyandstyle": _("Beauty & Style"),
+  "factual/carsandmotors": _("Cars & Motors"),
+  "factual/cinema": _("Cinema"),
+  "factual/consumer": _("Consumer"),
+  "factual/crimeandjustice": _("Crime & Justice"),
+  "factual/disability": _("Disability"),
+  "factual/familiesandrelationships": _("Families & Relationships"),
+  "factual/foodanddrink": _("Food & Drink"),
+  "factual/healthandwellbeing": _("Health & Wellbeing"),
+  "factual/history": _("History"),
+  "factual/homesandgardens": _("Homes & Gardens"),
+  "factual/lifestories": _("Life Stories"),
+  "factual/money": _("Money"),
+  "factual/petsandanimals": _("Pets & Animals"),
+  "factual/politics": _("Politics"),
+  "factual/sciencenatureandenvironment": _("Science, Nature & Environment"),
+  "factual/travel": _("Travel"),
+  "learning": _("Learning"),
+  "learning/1119": _("Age 11-19"),
+  "learning/511": _("Age 5-11"),
+  "learning/adults": _("Adults"),
+  "learning/preschool": _("Pre-School"),
+  "music": _("Music"),
+  "music/classicpopandrock": _("Classic Pop & Rock"),
+  "music/classical": _("Classical"),
+  "music/country": _("Country"),
+  "music/danceandelectronica": _("Dance & Electronica"),
+  "music/desi": _("Desi"),
+  "music/easylisteningsoundtracksandmusicals": _("Easy Listening, Soundtracks & Musicals"),
+  "music/folk": _("Folk"),
+  "music/hiphoprnbanddancehall": _("Hip Hop, RnB & Dancehall"),
+  "music/jazzandblues": _("Jazz & Blues"),
+  "music/popandchart": _("Pop & Chart"),
+  "music/rockandindie": _("Rock & Indie"),
+  "music/soulandreggae": _("Soul & Reggae"),
+  "music/world": _("World"),
+  "news": _("News"),
+  "religionandethics": _("Religion & Ethics"),
+  "sport": _("Sport"),
+  "sport/archery": _("Archery"),
+  "sport/athletics": _("Athletics"),
+  "sport/badminton": _("Badminton"),
+  "sport/baseball": _("Baseball"),
+  "sport/basketball": _("Basketball"),
+  "sport/bowls": _("Bowls"),
+  "sport/boxing": _("Boxing"),
+  "sport/canoeing": _("Canoeing"),
+  "sport/cricket": _("Cricket"),
+  "sport/cycling": _("Cycling"),
+  "sport/darts": _("Darts"),
+  "sport/disabilitysport": _("Disability Sport"),
+  "sport/diving": _("Diving"),
+  "sport/equestrian": _("Equestrian"),
+  "sport/fencing": _("Fencing"),
+  "sport/football": _("Football"),
+  "sport/gaelicgames": _("Gaelic Games"),
+  "sport/golf": _("Golf"),
+  "sport/gymnastics": _("Gymnastics"),
+  "sport/handball": _("Handball"),
+  "sport/hockey": _("Hockey"),
+  "sport/horseracing": _("Horse Racing"),
+  "sport/judo": _("Judo"),
+  "sport/modernpentathlon": _("Modern Pentathlon"),
+  "sport/motorsport": _("Motorsport"),
+  "sport/olympics": _("Olympics"),
+  "sport/rowing": _("Rowing"),
+  "sport/rugbyleague": _("Rugby League"),
+  "sport/rugbyunion": _("Rugby Union"),
+  "sport/sailing": _("Sailing"),
+  "sport/shinty": _("Shinty"),
+  "sport/shooting": _("Shooting"),
+  "sport/snooker": _("Snooker"),
+  "sport/softball": _("Softball"),
+  "sport/swimming": _("Swimming"),
+  "sport/tabletennis": _("Table Tennis"),
+  "sport/taekwondo": _("Taekwondo"),
+  "sport/tennis": _("Tennis"),
+  "sport/triathlon": _("Triathlon"),
+  "sport/volleyball": _("Volleyball"),
+  "sport/waterpolo": _("Water Polo"),
+  "sport/weightlifting": _("Weightlifting"),
+  "sport/wintersports": _("Winter Sports"),
+  "sport/wrestling": _("Wrestling"),
+  "weather": _("Weather")
+}
+
+# lowest = at the top
+shortref_to_sortrank_map = {
+  "news": 1,
+  "childrens": 2,
+  "drama": 3,
+  "entertainmentandcomedy": 4,
+  "factual": 5,
+  "learning": 6,
+  "music": 7,
+  "religionandethics": 8,
+  "sport": 9,
+  "weather": 10
+}
+
+'''
+GenrePool: keeps track of the already-created genres, mainly so we can easily
+           find already-existing parents for to-be-created genres
+''' 
+class GenrePool(object):
+    __slots__ = [ 'genres', 'toplevel_genres' ]
+
+    def __init__(self):
+        self.clear()
+
+    def clear(self):
+        self.genres = { } # maps short_ref => genre object
+
+    def get_genre(self, short_ref):
+        # check if genre already exists
+        if short_ref in self.genres:
+          return self.genres[short_ref]
+
+        # if not, create genre (and any parents which don't exist yet)
+        lastslash_pos = short_ref.rfind('/')
+        if lastslash_pos > 0:
+          parent_ref = short_ref[0:lastslash_pos]
+          gst.log('genre: ' + short_ref + ', parent_genre: ' + parent_ref)
+          parent = self.get_genre(parent_ref)
+        else:
+          parent = None
+
+        genre = Genre(short_ref, parent)
+        self.genres[short_ref] = genre
+
+        return genre
+
+    def get_toplevel_genres(self):
+        toplevel_genres = []
+        for genre in self.genres.values():
+          if not genre.parent:
+            toplevel_genres.append(genre)
+        return toplevel_genres
+
+'''
+Genre: represents a genre
+'''
+class Genre(object):
+    __slots__ = [ 'short_ref', 'label', 'sort_rank', 'parent',  'children', 'brands' ]
+
+    def __init__(self, short_ref, parent_genre):
+        self.short_ref = short_ref
+
+        if short_ref in shortref_to_label_map:
+          self.label = shortref_to_label_map[short_ref]
+        else:
+          self.label = _('Unknown: %s') % short_ref
+
+        if short_ref in shortref_to_sortrank_map:
+          self.sort_rank = shortref_to_sortrank_map[short_ref]
+        else:
+          self.sort_rank = 99999
+
+        self.parent = parent_genre
+        self.children = []
+        self.brands = []
+
+        if parent_genre is not None:
+          parent_genre.add_child(self)
+
+        gst.log('created genre ' + short_ref + ' = ' + self.label)
+
+    def add_child(self, child_genre):
+        if child_genre not in self.children:
+          self.children.append(child_genre)
+
+    def add_brand(self, brand):
+        if brand not in self.brands and brand.title is not None:
+            self.brands.append(brand)
+            gst.log(self.short_ref + ': adding show ' + brand.title)
+
+if __name__ == "__main__":
+  pass
+
